{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d09228-cf88-42c1-8659-1be1507da0fd",
   "metadata": {
    "id": "99d09228-cf88-42c1-8659-1be1507da0fd",
    "outputId": "34021331-3400-438f-ac3d-019d561f927c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install mediapipe\\n!pip install seaborn\\n!pip install tensorflow\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install mediapipe\n",
    "!pip install seaborn\n",
    "!pip install tensorflow\n",
    "!pip install openpyxl\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074bf6d5-fda0-4802-9cd8-c5d9f5394aa1",
   "metadata": {
    "id": "074bf6d5-fda0-4802-9cd8-c5d9f5394aa1"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "#RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54f860-95f5-4384-a8f7-50e66baf33d4",
   "metadata": {
    "id": "cd54f860-95f5-4384-a8f7-50e66baf33d4"
   },
   "outputs": [],
   "source": [
    "# Create a object from Holistic to detect (pose, face, and hands keypoints)\n",
    "mp_holistic = mp.solutions.holistic\n",
    "# Drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c7aaa-7672-47c8-b0c6-6124b2d178f9",
   "metadata": {
    "id": "086c7aaa-7672-47c8-b0c6-6124b2d178f9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The input image is converted from BGR to RGB because the MediaPipe model expects RGB images.\n",
    "It sets image.flags.writeable to False before passing it to the model to prevent any unwanted modifications during the inference process.\n",
    "The images will converted back from RGB to BGR for any further OpenCV operations,\n",
    "this ensures the image can be processed further by OpenCV without any issues related to color formats.\n",
    "'''\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad99160-775c-4726-b9bb-6050956b62d4",
   "metadata": {
    "id": "aad99160-775c-4726-b9bb-6050956b62d4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function is responsible for drawing the detected landmarks on the image, allowing you to imagen the pose and hand landmarks detected by MediaPipe.\n",
    "\n",
    "The function draws the pose landmarks, left hand landmarks, and right hand landmarks with different colors and styles.\n",
    "\n",
    "color: Defines the color of the landmarks.\n",
    "thickness: Defines how thick the lines connecting the landmarks will be.\n",
    "circle_radius: Controls the radius of the circles around each landmark.\n",
    "\n",
    "This will makes it easier to detected landmarks on the image for debugging or interpretation purposes.\n",
    "'''\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    # Draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20140aa4-9d63-4505-b6c8-d4345e63ac7a",
   "metadata": {
    "id": "20140aa4-9d63-4505-b6c8-d4345e63ac7a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function adjusts the landmarks by centering them around a specific point LikeTHE ( the nose or wrist)\n",
    "that's to normalize the positions and remove any translation shift in the data.\n",
    "\n",
    "Reshape>> for thhe landmark array is reshaped to handle 3D points (x, y, z).\n",
    "\n",
    "Centering>> Like (nose or wrist) is subtracted from each landmark to \"center\" the landmarks around the specific point.\n",
    "It's look like Normalization :)\n",
    "'''\n",
    "\n",
    "def adjust_landmarks(arr,center):\n",
    "\n",
    "    # Reshape the array to have shape (n, 3)\n",
    "    arr_reshaped = arr.reshape(-1, 3)\n",
    "\n",
    "    # Repeat the center array to have shape (n, 3)\n",
    "    center_repeated = np.tile(center, (len(arr_reshaped), 1))\n",
    "\n",
    "    # Subtract the center array from the arr array\n",
    "    arr_adjusted = arr_reshaped - center_repeated\n",
    "\n",
    "    # Reshape arr_adjusted back to shape (n*3,)\n",
    "    arr_adjusted = arr_adjusted.reshape(-1)\n",
    "    return(arr_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d25f41-27c2-4879-8f33-0a0d1c905f84",
   "metadata": {
    "id": "67d25f41-27c2-4879-8f33-0a0d1c905f84"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function extracts and adjusts keypoints:\n",
    "Pose, Left Hand, Right Hand Keypoints: Each set of landmarks (pose, left hand, right hand) is flattened into a 1D array.\n",
    "Also the landmarks are adjusted by centering around specific points (nose for pose, wrists for hands).\n",
    "So. it's to extract and adjust the keypoints for each frame, making them ready for further analysis or machine learning models.\n",
    "'''\n",
    "\n",
    "def extract_keypoints(results):\n",
    "\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    nose=pose[:3]\n",
    "    lh_wrist=lh[:3]\n",
    "    rh_wrist=rh[:3]\n",
    "    pose_adjusted = adjust_landmarks(pose,nose)\n",
    "    lh_adjusted = adjust_landmarks(lh,lh_wrist)\n",
    "    rh_adjusted = adjust_landmarks(rh,rh_wrist)\n",
    "    return pose_adjusted, lh_adjusted, rh_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973ed1a3-c596-409f-8aef-c9852ef03f96",
   "metadata": {
    "id": "973ed1a3-c596-409f-8aef-c9852ef03f96",
    "outputId": "37a63da1-88ea-4efa-de7c-189f85e68516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0013', '0014', '0015', '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025', '0026', '0027', '0028', '0029', '0030', '0031', '0071', '0072', '0073', '0074', '0075', '0076', '0077', '0078', '0079', '0080', '0081', '0082', '0083', '0084', '0085', '0086', '0087', '0088', '0089', '0090', '0091', '0092', '0093', '0094', '0095', '0096', '0097', '0098', '0099', '0100', '0101', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0110', '0111', '0112', '0113', '0114', '0115', '0116', '0117', '0118', '0119', '0120', '0121', '0122', '0123', '0124', '0125', '0126', '0127', '0128', '0129', '0130', '0131', '0132', '0133', '0134', '0135', '0136', '0137', '0138', '0139', '0140', '0141', '0142', '0143', '0144', '0145', '0146', '0147', '0148', '0149', '0150', '0151', '0152', '0153', '0154', '0155', '0156', '0157', '0158', '0159', '0160', '0161', '0162', '0163', '0164', '0165', '0166', '0167', '0168', '0169', '0170', '0171', '0172', '0173', '0174', '0175', '0176', '0177', '0178', '0179', '0180', '0181', '0182', '0183', '0184', '0185', '0186', '0187', '0188', '0189', '0190', '0191', '0192', '0193', '0194', '0195', '0196', '0197', '0198', '0199', '0200', '0201', '0202', '0203', '0204', '0205', '0206', '0207', '0208', '0209', '0210', '0211', '0212', '0213', '0214', '0215', '0216', '0217', '0218', '0219', '0220', '0221', '0222', '0223', '0224', '0225', '0226', '0227', '0228', '0229', '0230', '0231', '0232', '0233', '0234', '0235', '0236', '0237', '0238', '0239', '0240', '0241', '0242', '0243', '0244', '0245', '0246', '0247', '0248', '0249', '0250', '0251', '0252', '0253', '0254', '0255', '0256', '0257', '0258', '0259', '0260', '0261', '0262', '0263', '0264', '0265', '0266', '0267', '0268', '0269', '0270', '0271', '0272', '0273', '0274', '0275', '0276', '0277', '0278', '0279', '0280', '0281', '0282', '0283', '0284', '0285', '0286', '0287', '0288', '0289', '0290', '0291', '0292', '0293', '0294', '0295', '0296', '0297', '0298', '0299', '0300', '0301', '0302', '0303', '0304', '0305', '0306', '0307', '0308', '0309', '0310', '0311', '0312', '0313', '0314', '0315', '0316', '0317', '0318', '0319', '0320', '0321', '0322', '0323', '0324', '0325', '0326', '0327', '0328', '0329', '0330', '0331', '0332', '0333', '0334', '0335', '0336', '0337', '0338', '0339', '0340', '0341', '0342', '0343', '0344', '0345', '0346', '0347', '0348', '0349', '0350', '0351', '0352', '0353', '0354', '0355', '0356', '0357', '0358', '0359', '0360', '0361', '0362', '0363', '0364', '0365', '0366', '0367', '0368', '0369', '0370', '0371', '0372', '0373', '0374', '0375', '0376', '0377', '0378', '0379', '0380', '0381', '0382', '0383', '0384', '0385', '0386', '0387', '0388', '0389', '0390', '0391', '0392', '0393', '0394', '0395', '0396', '0397', '0398', '0399', '0400', '0401', '0402', '0403', '0404', '0405', '0406', '0407', '0408', '0409', '0410', '0411', '0412', '0413', '0414', '0415', '0416', '0417', '0418', '0419', '0420', '0421', '0422', '0423', '0424', '0425', '0426', '0427', '0428', '0429', '0430', '0431', '0432', '0433', '0434', '0435', '0436', '0437', '0438', '0439', '0440', '0441', '0442', '0443', '0444', '0445', '0446', '0447', '0448', '0449', '0450', '0451', '0452', '0453', '0454', '0455', '0456', '0457', '0458', '0459', '0460', '0461', '0462', '0463', '0464', '0465', '0466', '0467', '0468', '0469', '0470', '0471', '0472', '0473', '0474', '0475', '0476', '0477', '0478', '0479', '0480', '0481', '0482', '0483', '0484', '0485', '0486', '0487', '0488', '0489', '0490', '0491', '0492', '0493', '0494', '0495', '0496', '0497', '0498', '0499', '0500', '0501', '0502']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I have to adjust the range to fit the words and numbers :) #############\n",
    "'''\n",
    "# RUN\n",
    "# Define the different ranges that needed\n",
    "ranges = [(1, 32), (71, 503)]  # (1, 32) represents numbers, (71, 503) represents Words\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "selected_words = []\n",
    "\n",
    "# Iterate over each range\n",
    "for start, end in ranges:\n",
    "    # Extend the list with zero-padded numbers in the current range\n",
    "    selected_words.extend([str(num).zfill(4) for num in range(start, end)])\n",
    "\n",
    "# Print the result\n",
    "print(selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa89e31-3ae1-4ab7-a5a2-ce9af57cc300",
   "metadata": {
    "id": "eaa89e31-3ae1-4ab7-a5a2-ce9af57cc300"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function processes all the video frames of sign language sings for a particular signer and split (train, test, or val).\n",
    "It does the following:\n",
    "\n",
    "For each word, it processes video files.\n",
    "\n",
    "For each frame in the video, the function:\n",
    ">> Reads the frame.\n",
    "\n",
    ">> Uses mediapipe_detection to detect landmarks.\n",
    "\n",
    ">> Extracts the keypoints (pose, left hand, right hand).\n",
    "\n",
    ">> Appends the keypoints to the respective lists.\n",
    "\n",
    ">> After processing a video, the keypoints are saved as .npy files.\n",
    "\n",
    "\n",
    "This function generates numpy arrays of keypoints for each video in the specified folder location.\n",
    "Args:\n",
    "    signer(int): the signer of interest. Could be 01 or 02 or 03\n",
    "    split(str): can be 'train', 'test' or 'val'\n",
    "'''\n",
    "def make_keypoint_arrays(path,signer,split):\n",
    "\n",
    "    os.makedirs('karsl-502',exist_ok = True)\n",
    "    os.makedirs(f'karsl-502/{signer}',exist_ok = True)\n",
    "    os.makedirs(f'karsl-502/{signer}/{split}',exist_ok = True)\n",
    "    working_path = f'karsl-502/{signer}/{split}'\n",
    "    words_folder = os.path.join(path,str(signer),str(signer), split)\n",
    "\n",
    "    # Loop through all the subfolders in the folder\n",
    "    for word in tqdm(selected_words):\n",
    "\n",
    "        video_files = os.listdir(os.path.join(words_folder, word))\n",
    "          # Loop through the video files\n",
    "        for video_file in video_files:\n",
    "                # Open the video file\n",
    "            video = sorted(os.listdir(os.path.join(words_folder, word, video_file)))\n",
    "\n",
    "            # Initialize the list of keypoints for this video\n",
    "            pose_keypoints, lh_keypoints, rh_keypoints = [], [], []\n",
    "            with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "              # Loop through the video frames\n",
    "              for frame in video:\n",
    "                  # Perform any necessary preprocessing on the frame (e.g., resizing, normalization)\n",
    "                frame = os.path.join(words_folder, word, video_file,frame)\n",
    "                frame = cv2.imread(frame)\n",
    "#                 frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                  # Normalize pixel values to the range [0, 1]\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                # Extract keypoints\n",
    "                pose, lh, rh = extract_keypoints(results)\n",
    "                # Add the keypoints to the list for this video\n",
    "                pose_keypoints.append(pose)\n",
    "                lh_keypoints.append(lh)\n",
    "                rh_keypoints.append(rh)\n",
    "                # Save the keypoints for this video to a numpy array\n",
    "                pose_directory = os.path.join(working_path, word,'pose_keypoints')\n",
    "                lh_directory = os.path.join(working_path, word,'lh_keypoints')\n",
    "                rh_directory = os.path.join(working_path, word,'rh_keypoints')\n",
    "\n",
    "                if not os.path.exists(pose_directory):\n",
    "                    os.makedirs(pose_directory)\n",
    "\n",
    "                if not os.path.exists(lh_directory):\n",
    "                    os.makedirs(lh_directory)\n",
    "\n",
    "                if not os.path.exists(rh_directory):\n",
    "                    os.makedirs(rh_directory)\n",
    "\n",
    "                pose_path = os.path.join(pose_directory, video_file)\n",
    "                np.save(pose_path, pose_keypoints)\n",
    "\n",
    "                lh_path = os.path.join(lh_directory, video_file)\n",
    "                np.save(lh_path, lh_keypoints)\n",
    "\n",
    "                rh_path = os.path.join(rh_directory, video_file)\n",
    "                np.save(rh_path, rh_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efe706-d991-4768-a3f7-5a1b725958ed",
   "metadata": {
    "id": "48efe706-d991-4768-a3f7-5a1b725958ed",
    "outputId": "834ab4e3-c16e-4347-bb0a-a29e13885a9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 463/463 [14:59:06<00:00, 116.52s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 463/463 [5:03:00<00:00, 39.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 463/463 [21:05:57<00:00, 164.05s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 463/463 [4:05:33<00:00, 31.82s/it]\n"
     ]
    }
   ],
   "source": [
    "#make_keypoint_arrays('G:\\Capstone data\\karsl-502','01','train')\n",
    "#make_keypoint_arrays('G:\\Capstone data\\karsl-502','01','test')\n",
    "#make_keypoint_arrays('G:\\Capstone data\\karsl-502','02','train')\n",
    "#make_keypoint_arrays('G:\\Capstone data\\karsl-502','02','test')\n",
    "#make_keypoint_arrays('G:\\Capstone data\\karsl-502','03','train')\n",
    "#make_keypoint_arrays('G:\\Capstone data\\karsl-502','03','test')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
